# GenAI Toolbox SDK

This SDK allows you to seamlessly integrate the functionalities of
[Toolbox](https://github.com/googleapis/genai-toolbox) into your LLM
applications, enabling advanced orchestration and interaction with GenAI models.

<!-- TOC -->

- [GenAI Toolbox SDK](#genai-toolbox-sdk)
    - [Installation](#installation)
    - [Usage](#usage)
    - [Load a toolset](#load-a-toolset)
    - [Load a single tool](#load-a-single-tool)
    - [Use with LangChain](#use-with-langchain)
    - [Use with LangGraph](#use-with-langgraph)
        - [Represent Tools as Nodes](#represent-tools-as-nodes)
        - [Connect Tools with LLM](#connect-tools-with-llm)
    - [Manual usage](#manual-usage)

<!-- /TOC -->
## Installation

> [!IMPORTANT]
> This SDK is not yet available on PyPI. For now, install it from source by following these [installation instructions](DEVELOPER.md).

You can install the Toolbox SDK for LangChain using `pip`.

```bash
pip install toolbox-langchain-sdk
```

## Usage

Import and initialize the toolbox client.

```python
from toolbox_langchain_sdk import ToolboxClient

# Replace with your Toolbox service's URL
toolbox = ToolboxClient("http://localhost:5000")
```

> [!TIP]
> You can also pass your own `ClientSession` so that the `ToolboxClient` can
> reuse the same session.
> ```
> async with ClientSession() as session:
>   client = ToolboxClient(http://localhost:5000, session)
> ```

## Load a toolset

You can load a toolset, a collection of related tools.

```python
# Load all tools
tools = await toolbox.load_toolset()

# Load a specific toolset
tools = await toolbox.load_toolset("my-toolset")
```

## Load a single tool

You can also load a single tool.

```python
tool = await toolbox.load_tool("my-tool")
```

## Use with LangChain

LangChain's agents can dynamically choose and execute tools based on the user
input. The user can include the tools loaded from the Toolbox SDK in the agent's
toolkit.

```python
from langchain_google_vertexai import ChatVertexAI
from langchain.agents import initialize_agent

model = ChatVertexAI()

# Initialize agent with tools
agent = initialize_agent(tools, model)

# Run the agent
agent.run("Do something with the tools")
```

## Use with LangGraph

The Toolbox SDK can be seamlessly integrated with LangGraph to enable the use of
Toolbox service tools within a graph-based workflow. Using this SDK, we can
follow the [official guide](https://langchain-ai.github.io/langgraph/) with
minimal changes.

### Represent Tools as Nodes

Each tool generated by the SDK can be represented as a LangGraph node. The
node's functionality would encapsulate the execution of the corresponding tool.

```python
from toolbox_sdk import ToolboxClient
from langgraph.graph import StateGraph, MessagesState
from langgraph.prebuilt import ToolNode

# Define the function that calls the model
def call_model(state: MessagesState):
    messages = state['messages']
    response = model.invoke(messages)
    # We return a list, because this will get added to the existing list
    return {"messages": [response]}

model = ChatVertexAI()
builder = StateGraph()
tool_node = ToolNode(tools)

builder.add_node("agent", call_model)
builder.add_node("tools", tool_node)
```

### Connect Tools with LLM

Now we can connect the tool nodes with LLM nodes. The LLM can decide which tool
to use based on the user input or the context of the conversation. The output
from a tool can then be fed back into the LLM for further processing or
decision-making.

```python
from langgraph.graph import END, START

# Define the function that determines whether to continue or not
def should_continue(state: MessagesState) -> Literal["tools", END]:
    messages = state['messages']
    last_message = messages[-1]
    # If the LLM makes a tool call, then we route to the "tools" node
    if last_message.tool_calls:
        return "tools"
    # Otherwise, we stop (reply to the user)
    return END

builder.add_edge(START, "agent")
builder.add_conditional_edges(
    "agent",
    should_continue,
)
builder.add_edge("tools", 'agent')

graph = builder.compile()
```

## Manual usage

You can also execute a tool manually using the `arun` method.

```python
result = await tools[0].arun({ "name": "Alice", "age": 30 })
```
